\begin{tabular}{lrrrrrrrrr}
\toprule
 & our-FLAN & vanilla-FLAN & delta-FLAN & our-WMT19 & vanilla-WMT19 & delta-WMT19 & our-GIGAWORD & vanilla-GIGAWORD & delta-GIGAWORD \\
model &  &  &  &  &  &  &  &  &  \\
\midrule
MBZUAI/LaMini-GPT-1.5B & 0.0055 & 0.0643 & 0.0588 & 0.0150 & 0.1353 & 0.1202 & 0.0063 & 0.0104 & 0.0041 \\
MBZUAI/LaMini-GPT-124M & 0.0027 & 0.0679 & 0.0652 & 0.0108 & 0.1151 & 0.1043 & 0.0037 & 0.0198 & 0.0161 \\
MBZUAI/LaMini-GPT-774M & 0.0054 & 0.0638 & 0.0584 & 0.0093 & 0.1074 & 0.0981 & 0.0019 & 0.0074 & 0.0055 \\
ai-forever/mGPT & 0.0035 & 0.0050 & 0.0015 & 0.0049 & 0.0153 & 0.0104 & 0.0119 & 0.0119 & 0.0000 \\
cerebras/Cerebras-GPT-1.3B & 0.0038 & 0.0188 & 0.0150 & 0.0131 & 0.0618 & 0.0488 & 0.0048 & 0.0159 & 0.0111 \\
cerebras/Cerebras-GPT-111M & 0.0096 & 0.0601 & 0.0505 & 0.0098 & 0.1129 & 0.1032 & 0.0038 & 0.0219 & 0.0181 \\
cerebras/Cerebras-GPT-2.7B & 0.0030 & 0.0033 & 0.0003 & 0.0114 & 0.0124 & 0.0010 & 0.0020 & 0.0022 & 0.0002 \\
cerebras/Cerebras-GPT-256M & 0.0105 & 0.0517 & 0.0412 & 0.0095 & 0.0874 & 0.0780 & 0.0022 & 0.0137 & 0.0115 \\
facebook/bart-base & 0.0073 & 0.0506 & 0.0433 & 0.0201 & 0.1075 & 0.0873 & 0.0194 & 0.0247 & 0.0052 \\
facebook/bart-large & 0.0129 & 0.0388 & 0.0259 & 0.0123 & 0.1070 & 0.0947 & 0.0055 & 0.0068 & 0.0013 \\
facebook/bart-large-cnn & 0.0115 & 0.0114 & -0.0001 & 0.0115 & 0.0747 & 0.0632 & 0.0053 & 0.0059 & 0.0006 \\
facebook/bart-large-xsum & 0.0090 & 0.0357 & 0.0267 & 0.0089 & 0.1011 & 0.0922 & 0.0039 & 0.0046 & 0.0007 \\
facebook/opt-1.3b & 0.0024 & 0.0164 & 0.0140 & 0.0150 & 0.0709 & 0.0558 & 0.0024 & 0.0034 & 0.0010 \\
facebook/opt-2.7b & 0.0052 & 0.0072 & 0.0020 & 0.0229 & 0.0602 & 0.0373 & 0.0012 & 0.0018 & 0.0006 \\
facebook/opt-350m & 0.0078 & 0.0478 & 0.0400 & 0.0135 & 0.0848 & 0.0712 & 0.0045 & 0.0055 & 0.0010 \\
facebook/opt-6.7b & 0.0025 & 0.0026 & 0.0002 & 0.0073 & 0.0090 & 0.0016 & 0.0028 & 0.0030 & 0.0002 \\
google/mt5-base & 0.0035 & 0.0136 & 0.0101 & 0.0066 & 0.0155 & 0.0088 & 0.0055 & 0.0277 & 0.0221 \\
google/mt5-large & 0.0027 & 0.0119 & 0.0091 & 0.0045 & 0.0249 & 0.0204 & 0.0024 & 0.0071 & 0.0046 \\
google/switch-base-16 & 0.0088 & 0.0284 & 0.0195 & 0.0154 & 0.0171 & 0.0017 & 0.0082 & 0.0074 & -0.0008 \\
google/switch-base-32 & 0.0103 & 0.0307 & 0.0204 & 0.0048 & 0.0058 & 0.0010 & 0.0109 & 0.0132 & 0.0023 \\
google/switch-base-8 & 0.0073 & 0.0298 & 0.0225 & 0.0098 & 0.0104 & 0.0006 & 0.0096 & 0.0110 & 0.0014 \\
google/t5-v1_1-base & 0.0069 & 0.0456 & 0.0386 & 0.0117 & 0.0358 & 0.0241 & 0.0056 & 0.0056 & 0.0000 \\
gpt2 & 0.0075 & 0.0697 & 0.0622 & 0.0089 & 0.1007 & 0.0918 & 0.0030 & 0.0190 & 0.0160 \\
gpt2-large & 0.0056 & 0.0593 & 0.0537 & 0.0152 & 0.0893 & 0.0740 & 0.0035 & 0.0076 & 0.0041 \\
gpt2-medium & 0.0038 & 0.0676 & 0.0639 & 0.0059 & 0.0991 & 0.0932 & 0.0020 & 0.0044 & 0.0024 \\
gpt2-xl & 0.0064 & 0.0614 & 0.0550 & 0.0410 & 0.1281 & 0.0871 & 0.0047 & 0.0104 & 0.0057 \\
microsoft/phi-1_5 & 0.0112 & 0.0363 & 0.0251 & 0.0110 & 0.0366 & 0.0256 & 0.0029 & 0.0030 & 0.0001 \\
microsoft/phi-2 & 0.0060 & 0.0197 & 0.0137 & 0.0101 & 0.0317 & 0.0216 & 0.0040 & 0.0049 & 0.0008 \\
t5-base & 0.0078 & 0.0316 & 0.0238 & 0.0144 & 0.0151 & 0.0007 & 0.0026 & 0.0134 & 0.0108 \\
t5-small & 0.0039 & 0.0241 & 0.0202 & 0.0135 & 0.0141 & 0.0007 & 0.0079 & 0.0235 & 0.0156 \\
\bottomrule
\end{tabular}
